{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML classification Models on the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Lenovo\\Documents\\jupyter notebook DATA SCIENCE\\Unsupervised Lerarning\\Mypracise\\NLP Project - Covid Tweets Sentiment Analysis\\Corona_NLP_train.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8',\n",
       "       'advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order',\n",
       "       'Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P',\n",
       "       ...,\n",
       "       'You know itÂ\\x92s getting tough when @KameronWilds  is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!',\n",
       "       'Is it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus',\n",
       "       \"@TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['OriginalTweet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName          int64\n",
       "ScreenName        int64\n",
       "Location         object\n",
       "TweetAt          object\n",
       "OriginalTweet    object\n",
       "Sentiment        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia: Woolworths to give elde...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me, ready to go at supermarket during the #COV...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know itÂs getting tough when @KameronWild...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156    @TartiiCat Well new/used Rift S are going for ...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['OriginalTweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Tweets from the data for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia: Woolworths to give elde...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me, ready to go at supermarket during the #COV...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know itÂs getting tough when @KameronWild...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156    @TartiiCat Well new/used Rift S are going for ...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = data.OriginalTweet\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the data and then joining them back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia : Woolworths to give eld...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me , ready to go at supermarket during the #CO...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know itÂ  s getting tough when @KameronWi...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156    @TartiiCat Well new / used Rift S are going fo...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import TweetTokenizer\n",
    "tk = TweetTokenizer()\n",
    "tweets = tweets.apply(lambda x: tk.tokenize(x)).apply(lambda x : ' '.join(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Urls and Html links from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(tweets):\n",
    "    url_remove = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_remove.sub(r'', tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               @MeNyrbie @Phil_Gahan @Chrisitv  and  and \n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia : Woolworths to give eld...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me , ready to go at supermarket during the #CO...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know itÂ  s getting tough when @KameronWi...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156    @TartiiCat Well new / used Rift S are going fo...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.apply(lambda x:remove_urls(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML Removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(tweets):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               @MeNyrbie @Phil_Gahan @Chrisitv  and  and \n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia : Woolworths to give eld...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me , ready to go at supermarket during the #CO...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know itÂ  s getting tough when @KameronWi...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156    @TartiiCat Well new / used Rift S are going fo...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.apply(lambda x: remove_html(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Shortwords and Punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing symbols and punctuations from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    MeNyrbie Phil Gahan Chrisitv and and \n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia Woolworths to give elder...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me ready to go at supermarket during the COVID...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know it s getting tough when KameronWilds ...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156     TartiiCat Well new used Rift S are going for ...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.str.replace('[^a-zA-Z]+', ' ')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Shortwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     MeNyrbie Phil Gahan Chrisitv and and\n",
       "1        advice Talk your neighbours family exchange ph...\n",
       "2        Coronavirus Australia Woolworths give elderly ...\n",
       "3        food stock not the only one which empty PLEASE...\n",
       "4        ready supermarket during the COVID outbreak No...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering stock supermarket shel...\n",
       "41153    Response complaint not provided citing COVID r...\n",
       "41154    You know getting tough when KameronWilds ratio...\n",
       "41155    wrong that the smell hand sanitizer starting t...\n",
       "41156    TartiiCat Well new used Rift are going for Ama...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#Removing small words from the tweets (words which has length <= 3)\n",
    "tweets = tweets.apply(lambda x: ' '.join([w for w in word_tokenize(x) if len(w) >= 3]))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      menyrbi phil gahan chrisitv and and\n",
       "1        advic talk your neighbour famili exchang phone...\n",
       "2        coronavirus australia woolworth give elder dis...\n",
       "3        food stock not the onli one which empti pleas ...\n",
       "4        readi supermarket dure the covid outbreak not ...\n",
       "                               ...                        \n",
       "41152    airlin pilot offer stock supermarket shelv loc...\n",
       "41153    respons complaint not provid cite covid relat ...\n",
       "41154    you know get tough when kameronwild ration toi...\n",
       "41155    wrong that the smell hand sanit start turn cor...\n",
       "41156    tartiicat well new use rift are go for amazon ...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming the tweets\n",
    "from nltk.stem import SnowballStemmer \n",
    "stemmer = SnowballStemmer('english')\n",
    "tweets = tweets.apply(lambda x: [stemmer.stem(i.lower()) for i in tk.tokenize(x)]).apply(lambda x: ' '.join(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              menyrbi phil gahan chrisitv\n",
       "1        advic talk neighbour famili exchang phone numb...\n",
       "2        coronavirus australia woolworth give elder dis...\n",
       "3        food stock onli one empti pleas panic enough f...\n",
       "4        readi supermarket dure covid outbreak becaus p...\n",
       "                               ...                        \n",
       "41152    airlin pilot offer stock supermarket shelv loc...\n",
       "41153    respons complaint provid cite covid relat dela...\n",
       "41154    know get tough kameronwild ration toilet paper...\n",
       "41155    wrong smell hand sanit start turn coronavirus ...\n",
       "41156    tartiicat well new use rift go amazon although...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing stopwords from the tweets\n",
    "from nltk.corpus import stopwords \n",
    "stop = stopwords.words('english')\n",
    "tweets = tweets.apply(lambda x: [i for i in word_tokenize(x) if i not in stop]).apply(lambda x: ' '.join(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing tweets columns from the merged data with processed tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>menyrbi phil gahan chrisitv</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworth give elder dis...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>food stock onli one empti pleas panic enough f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>readi supermarket dure covid outbreak becaus p...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airlin pilot offer stock supermarket shelv loc...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>respons complaint provid cite covid relat dela...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>know get tough kameronwild ration toilet paper...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>wrong smell hand sanit start turn coronavirus ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>tartiicat well new use rift go amazon although...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0                            menyrbi phil gahan chrisitv             Neutral  \n",
       "1      advic talk neighbour famili exchang phone numb...            Positive  \n",
       "2      coronavirus australia woolworth give elder dis...            Positive  \n",
       "3      food stock onli one empti pleas panic enough f...            Positive  \n",
       "4      readi supermarket dure covid outbreak becaus p...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  airlin pilot offer stock supermarket shelv loc...             Neutral  \n",
       "41153  respons complaint provid cite covid relat dela...  Extremely Negative  \n",
       "41154  know get tough kameronwild ration toilet paper...            Positive  \n",
       "41155  wrong smell hand sanit start turn coronavirus ...             Neutral  \n",
       "41156  tartiicat well new use rift go amazon although...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.OriginalTweet = tweets\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null value replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName            0\n",
       "ScreenName          0\n",
       "Location         8590\n",
       "TweetAt             0\n",
       "OriginalTweet       0\n",
       "Sentiment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName          int64\n",
       "ScreenName        int64\n",
       "Location         object\n",
       "TweetAt          object\n",
       "OriginalTweet    object\n",
       "Sentiment        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              London\n",
       "1                                  UK\n",
       "2                           Vagabonds\n",
       "3                                 NaN\n",
       "4                                 NaN\n",
       "                     ...             \n",
       "41152    Wellington City, New Zealand\n",
       "41153                             NaN\n",
       "41154                             NaN\n",
       "41155                             NaN\n",
       "41156    i love you so much || he/him\n",
       "Name: Location, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location'].fillna(data['Location'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName         0\n",
       "ScreenName       0\n",
       "Location         0\n",
       "TweetAt          0\n",
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
       "       'Extremely Positive'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets encode Neutral as 0 , Negative as 1 and Positive as 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_map = {'Neutral':0, 'Positive':2, 'Extremely Negative':1, 'Negative':1,\n",
    "       'Extremely Positive':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        1\n",
       "        ..\n",
       "41152    0\n",
       "41153    1\n",
       "41154    2\n",
       "41155    0\n",
       "41156    1\n",
       "Name: Sentiment, Length: 41157, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'] = data['Sentiment'].map(sent_map)\n",
    "data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"C:\\Users\\Lenovo\\Documents\\jupyter notebook DATA SCIENCE\\Unsupervised Lerarning\\Mypracise\\NLP Project - Covid Tweets Sentiment Analysis\\pdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing the tweets using TFIDFVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(stop_words = stop)\n",
    "data_vec = vec.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41157x41274 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 689930 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Seperating label y from the train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.Sentiment\n",
    "y = y.values\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    18046\n",
       "1    15398\n",
       "0     7713\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Value counts of 0 and 1 to check the imbalance of the data\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the train data into X_train, y_train (train_set), X_test, y_test (test_set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_vec, y, test_size = 0.2, stratify = y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling the train set to overcome imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "model = LogisticRegression()\n",
    "model.fit(X_res, y_res)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762390670553936"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, pos_label='positive',average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X_res, y_res)\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7284985422740524"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred2,pos_label='positive',average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model3 = XGBClassifier()\n",
    "model3.fit(X_res, y_res)\n",
    "y_pred3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7526724975704567"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred3,pos_label='positive',average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC  \n",
    "model4= SVC()\n",
    "model4.fit(X_res,y_res)\n",
    "y_pred4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792031098153547"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred4,pos_label='positive',average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum f1 score is for Support Vector Machine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Saving the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Lenovo\\\\Documents\\\\jupyter notebook DATA SCIENCE\\\\Unsupervised Lerarning\\\\Mypracise\\\\NLP Project - Covid Tweets Sentiment Analysis\\\\svmModel.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model4,r'C:\\Users\\Lenovo\\Documents\\jupyter notebook DATA SCIENCE\\Unsupervised Lerarning\\Mypracise\\NLP Project - Covid Tweets Sentiment Analysis\\svmModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
